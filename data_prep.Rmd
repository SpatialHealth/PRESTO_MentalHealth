---
title: "data_prep"
author: "Cam Reimer"
date created: "2/4/2023"
last updated: "1/9/2024"
output: html_document
---

```{r load in data}
# navigate to directory 
setwd("C:/Users/camer/OneDrive/Documents/SPH/PRESTO")
# load in packages 
library(tidyverse)
library(lubridate)
library(dplyr)
library(labelled)
library(tidyr)
library(sas7bdat)
library(haven)
library(kableExtra)
library(VIM)
# load in functions
source("~/R/PRESTO_MentalHealth/data_prep_functions.R")
# path to full data set 
data_full <- read_sas("ndvi_mental_003.sas7bdat")
```

```{r Data Wrangling, Add NDVI}
years <- 2012:2019
buffers <- c(50,100,250,500)

# select important columns
data = data_full[c("StudyID", "Country", "state",  "ageatqstn", "b_race_ethnic_census", "b_educ", "b_income", "ct_HHinc", "ct_lths", "ct_urban", "pss_score", "b_mdi_score",  "b_finisheddate", 'b_walkwork', 'b_walkexer', 'b_walktrans', 'b_bike', 'b_freeweights', 'b_jogswimraq', 'b_aerobics', 'b_garden', 'b_livebirths', 'b_everpregnant', 'ttp_entry', 'geoflag', 'geoflag_b', 'b_smoke', 'alccat', 'b_unemp', 
#generate_all_ndvi_colnames(years,buffers)
grep(pattern = "(?:mean|max).*(?:201[2-9])", names(data_full), value = TRUE)
)]
#rm(data_full)

data$season <- get_seasons(date_vec = data$b_finisheddate)

# get NDVI - This may take a while
data <- add_ndvi(data, id_colname = "StudyID", date_colname = "b_finisheddate", buffers=buffers)

# categorize ct_urban
data <- add_urban_cat(data)
```

```{r, Add Exercise Data}
# convert exercise/activity hours 
rescale_met <- function(vec){
  out <- case_when(
    vec == 1 ~ 0,
    vec == 2 ~ 0.5, 
    vec == 3 ~ 1,
    vec == 4 ~ 2, 
    vec == 5 ~ 3.5,
    vec == 6 ~ 5.5, 
    vec == 7 ~ 7, 
    TRUE ~ NA
  )
  return(out)
}
exer_names <- c('b_walkwork', 'b_walkexer', 'b_walktrans', 'b_bike', 'b_freeweights', 'b_jogswimraq', 'b_aerobics', 'b_garden') #not including 'b_yoga'
scaling_factors <- c(2.0, 3.8, 2.5, 7.5, 4.5, 7.0, 6.5, 2.5) #2.5 for b_yoga

# re-scale individual met vars
data <- data |>
  mutate(across(all_of(exer_names), rescale_met))
data[exer_names] <- sweep(data[exer_names], MARGIN=2,scaling_factors, `*`)

# create composite met hours variable
data$b_totalmet <- apply(data[exer_names], sum, MARGIN = 1)
data <- data |>
  dplyr::select(!all_of(exer_names))
```

```{r Hot deck imputation}
outcomes <- c("pss_score", "b_mdi_score")
exposures <- names(data)[grep("ndvi", names(data))]
data_to_impute <- data |> tidyr::drop_na(all_of(c(outcomes, exposures))) |> dplyr::filter(!(geoflag_b %in% c(4,5,6,7,9)) & state != "AK" & state != "HI")
  
# impute covariates 
imp_vars <- c("b_income", "b_totalmet", "ct_HHinc", "ct_lths", "ct_urban_cat", "b_livebirths", "ttp_entry", "b_smoke", "alccat")
imputed <- hotdeck(data_to_impute,
                   variable = imp_vars,
                   #ord_var = c("ageatqstn", "b_race_ethnic_census", "b_educ"),
                   ord_var = "ageatqstn",
                   domain_var = c("b_race_ethnic_census", "b_educ"),
                   imp_var = FALSE) #|>
#   select(all_of(c('StudyID', imp_vars))) |>
#   rename_with(~ paste0(.x, "_imp"), all_of(imp_vars))
# 
# imputed <- left_join(data, imputed_covs, by = "StudyID")
```

```{r, Check for Missingness Sequentially}
# specify columns
confounding <- c("ageatqstn", "b_race_ethnic_census", "b_educ", "b_income", "season", "ct_HHinc", "ct_lths", "ct_urban_cat")
outcomes <- c("pss_score", "b_mdi_score")
exposures <- names(data)[grep("ndvi", names(data))]

# Initialize missing data table
missing <- data.frame(rep(NA, 14))
colnames(missing) <- '# of Participants w/ Missing Data'
rownames(missing) <- c('All Exposures', 'Out of Study Region', 'Cannot be accurately geocoded', 'Missing NDVI',
                       'All Outcomes', 'PSS','MDI Score',  
                       'All Confounders', 'Age', 'Race/Ethnicity', 'Education', 'Income', 'Season', 'Census-tract Measures')

# 1. Exposures 
geo1 <- data |> dplyr::filter(!(geoflag_b %in% c(5, 6)) & state != "AK" & state != "HI") 
geo2 <- geo1 |> dplyr::filter(!(geoflag_b %in% c(4, 7, 9)))
ex <- geo2 %>% dplyr::filter(complete.cases(select(., all_of(exposures))))
missing[1,] <- nrow(data) - nrow(ex)
missing[2,] <- nrow(data) - nrow(geo1)
missing[3,] <- nrow(geo1) - nrow(geo2)
missing[4,] <- nrow(geo2) - nrow(ex)

# 2. Outcomes 
out <- ex %>% dplyr::filter(complete.cases(select(., all_of(outcomes))))
pss <- ex %>% dplyr::filter(complete.cases(select(., "pss_score")))
mdi <- pss %>% dplyr::filter(complete.cases(select(., "b_mdi_score")))

missing[5,] <- nrow(ex) - nrow(out)
missing[6,] <- nrow(ex) - nrow(pss)
missing[7,] <- nrow(pss) - nrow(mdi)

# 3. Confounders 
con <- out %>% dplyr::filter(complete.cases(select(., all_of(confounding))))
age <- out %>% dplyr::filter(complete.cases(select(., "ageatqstn")))
race <- age %>% dplyr::filter(complete.cases(select(., "b_race_ethnic_census")))
educ <- race %>% dplyr::filter(complete.cases(select(., "b_educ")))
income <- educ %>% dplyr::filter(complete.cases(select(., "b_income")))
season <- income %>% dplyr::filter(complete.cases(select(., "season")))
ct <- season %>% dplyr::filter(complete.cases(select(., all_of(c("ct_urban_cat", "ct_lths", "ct_HHinc")))))

missing[8,] <- nrow(out) - nrow(con)
missing[9,] <- nrow(out) - nrow(age)
missing[10,] <- nrow(age) - nrow(race)
missing[11,] <- nrow(race) - nrow(educ)
missing[12,] <- nrow(educ) - nrow(income)
missing[13,] <- nrow(income) - nrow(season)
missing[14,] <- nrow(season) - nrow(ct)

# 4. Create table
kbl(missing, caption = '') %>%
  kable_paper("striped", full_width = F) %>%
  pack_rows("Exposures", 1, 4) %>%
  pack_rows("Outcomes", 5, 7) %>%
  pack_rows("Confounders", 8, 14)

### Drop NAs
# data_final <- data |> tidyr::drop_na(all_of(c(confounding, outcomes, exposures))) |> dplyr::filter(!(geoflag_b %in% c(4,5,6,7,9)))
# dropped <- subset(data, !(data$StudyID %in% data_final$StudyID))

# checks 
# if((nrow(data)-nrow(ct)) != nrow(dropped)){
#   paste0("ERROR: Some missing data is unaccounted for!")
# }

rm(ex, out, pss, mdi, con, age, race, educ, income, ct, season)
write.csv(missing, "C:/Users/camer/OneDrive/Documents/SPH/PRESTO/supplementary/missing_data.csv")
```

```{r, Drop Participants with missing data OR in AK/HI}
confounding <- c("ageatqstn", "b_race_ethnic_census", "b_educ", "b_income", "ct_HHinc", "ct_lths", "ct_urban_cat", "season")
outcomes <- c("pss_score", "b_mdi_score")
exposures <- names(data)[grep("ndvi", names(data))]

imputed_final <- imputed |> tidyr::drop_na(all_of(c(confounding, outcomes, exposures))) |> dplyr::filter(!(geoflag_b %in% c(4,5,6,7,9)) & state != "AK" & state != "HI")
imputed_dropped <- subset(data, !(data$StudyID %in% imputed_final$StudyID))

complete_final <- data |> tidyr::drop_na(all_of(c(confounding, outcomes, exposures))) |> dplyr::filter(!(geoflag_b %in% c(4,5,6,7,9)) & state != "AK" & state != "HI")
complete_dropped <- subset(data, !(data$StudyID %in% complete_final$StudyID))
```

```{r Get quantiles and assign factors}
### Get Quantiles
# GET NDVI IQR and Quartiles for raw NDVI and NDVI IQR
imputed_final <- process_ndvi(imputed_final, outpath = 'C:/Users/camer/OneDrive/Documents/SPH/PRESTO/imputed_breaks.csv') # saves NDVI quartile breaks
# Create Quantiles for NSES
imputed_final <- imputed_final %>% mutate(ct_HHinc_quantile = ntile(ct_HHinc, 3))

# GET NDVI IQR and Quartiles for raw NDVI and NDVI IQR
complete_final <- process_ndvi(complete_final, outpath = 'C:/Users/camer/OneDrive/Documents/SPH/PRESTO/complete_case_breaks.csv') # saves NDVI quartile breaks
# Create Quantiles for NSES
complete_final <- complete_final %>% mutate(ct_HHinc_quantile = ntile(ct_HHinc, 3))


### Convert Variables to factors 
factor_covs <- c("b_race_ethnic_census", "b_educ", "b_income", "ct_urban_cat", "b_unemp", "b_everpregnant", "season", "b_smoke", "alccat")
factor_vars <- c(factor_covs, names(imputed_final[grep("quantile", names(imputed_final))]))

# Imputed 
imputed_final[factor_vars] <- lapply(imputed_final[factor_vars], factor)
imputed_dropped[factor_covs] <- lapply(imputed_dropped[factor_covs], factor)

# Complete Cases
complete_final[factor_vars] <- lapply(complete_final[factor_vars], factor)
complete_dropped[factor_covs] <- lapply(complete_dropped[factor_covs], factor)
```

```{r, Prep for Sensitivity Analysis}
outcomes <- c("pss_score", "b_mdi_score")
exposures <- names(data)[grep("ndvi", names(data))]

# attempt time 
cycles_3 <- subset(imputed_final, imputed_final$ttp_entry < 3) |> tidyr::drop_na(all_of(c(outcomes, exposures)))
cycles_6 <- subset(imputed_final, imputed_final$ttp_entry < 6) |> tidyr::drop_na(all_of(c(outcomes, exposures))) 

# parity 
parous <- subset(imputed_final, imputed_final$b_livebirths > 0) |> tidyr::drop_na(all_of(c(outcomes, exposures)))
nulliparous <- subset(imputed_final, imputed_final$b_livebirths == 0) |> tidyr::drop_na(all_of(c(outcomes, exposures)))

# smoking 
smoking <- subset(imputed_final, as.numeric(imputed_final$b_smoke) < 3 ) |> tidyr::drop_na(all_of(c(outcomes, exposures)))
nonsmoking <- subset(imputed_final, as.numeric(imputed_final$b_smoke) == 3 ) |> tidyr::drop_na(all_of(c(outcomes, exposures)))

# alcohol use
alc_none <- subset(imputed_final, as.numeric(imputed_final$alccat) < 2) |> tidyr::drop_na(all_of(c(outcomes, exposures)))
alc_any <- subset(imputed_final, as.numeric(imputed_final$alccat) >= 2) |> tidyr::drop_na(all_of(c(outcomes, exposures)))

alc_lessthan_f3 <- subset(imputed_final, as.numeric(imputed_final$alccat) < 3) |> tidyr::drop_na(all_of(c(outcomes, exposures)))
alc_f3_or_more <- subset(imputed_final, as.numeric(imputed_final$alccat) >= 3) |> tidyr::drop_na(all_of(c(outcomes, exposures)))

# export 
save(cycles_3, cycles_6, parous, nulliparous, smoking, nonsmoking, 
     alc_none, alc_any, alc_lessthan_f3, alc_f3_or_more, 
     file = "C:/Users/camer/OneDrive/Documents/SPH/PRESTO/data/sensitivity_data.RData")
```

```{r Create subsets}
# by urbanicity 
urban = subset(imputed_final, ct_urban_cat == 1)
rural = subset(imputed_final, ct_urban_cat == 0)

# use census tract income as a proxy for Neighborhood Socioeconomic Status
NSES1 = subset(imputed_final, ct_HHinc_quantile == 1)
NSES2 = subset(imputed_final, ct_HHinc_quantile == 2)
NSES3 = subset(imputed_final, ct_HHinc_quantile == 3)

# combined stratification
NSES1_urban = subset(imputed_final, ct_HHinc_quantile == 1 & ct_urban_cat ==1)
NSES2_urban = subset(imputed_final, ct_HHinc_quantile == 2 & ct_urban_cat ==1)
NSES3_urban = subset(imputed_final, ct_HHinc_quantile == 3 & ct_urban_cat ==1)
NSES1_rural = subset(imputed_final, ct_HHinc_quantile == 1 & ct_urban_cat ==0)
NSES2_rural = subset(imputed_final, ct_HHinc_quantile == 2 & ct_urban_cat ==0)
NSES3_rural = subset(imputed_final, ct_HHinc_quantile == 3 & ct_urban_cat ==0)

```

```{r Export data}
imputed <- imputed_final
complete_cases <- complete_final 

save(imputed, urban, rural, NSES1, NSES2, NSES3, NSES1_urban, NSES2_urban, NSES3_urban, NSES1_rural, NSES2_rural, NSES3_rural,
     complete_cases, file = "C:/Users/camer/OneDrive/Documents/SPH/PRESTO/data/data_processed.RData")

save(imputed_dropped, complete_dropped, file = "C:/Users/camer/OneDrive/Documents/SPH/PRESTO/data/dropped.RData")
```


